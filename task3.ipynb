{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras import utils\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to image files\n",
    "infected_path = r'C:\\Users\\MQ0\\Downloads\\cell_images\\Parasitized'\n",
    "uninfected_path = r'C:\\Users\\MQ0\\Downloads\\cell_images\\Uninfected'\n",
    "\n",
    "# variables to store data\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# read in every image as numpy array\n",
    "label = 0\n",
    "for x in [uninfected_path,infected_path]:  \n",
    "    for im in os.listdir(x):\n",
    "        if 'Thumbs.db' not in im:\n",
    "            image = Image.open(x + '\\\\' + im).resize((50,50))\n",
    "            data.append(np.asarray(image))\n",
    "            labels.append(label)\n",
    "    label += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to numpy array\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, shuffle = True)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "First we train a Convolutional Model without Residual Connections, we will start with a simple model, and keep adding layers until there are no more improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a simple model\n",
    "def make_model(kernel_sizes = (3,3), dense = 64, filters = (32,32)):\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Conv2D(filters[0], kernel_size=kernel_sizes[0],activation='relu',input_shape=(50,50,3)))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn.add(Conv2D(filters[1], kernel_size=kernel_sizes[1], activation='relu'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(dense, activation='relu'))\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    cnn.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "    return cnn\n",
    "\n",
    "\n",
    "\n",
    "# parameters to tune\n",
    "filters = [(16,16),(32,32),(32,64)]\n",
    "kernel_sizes = [(3,3),(5,5),(7,7),(5,7),(3,5),(3,7)]\n",
    "dense = [512,256,128,64]\n",
    "config_list = []\n",
    "for x in kernel_sizes:\n",
    "    for y in dense:\n",
    "        for z in filters:\n",
    "            config_list += [[x,y,z]]\n",
    "\n",
    "# variables to store training results    \n",
    "validation_history = []        \n",
    "average_validation = np.empty((len(config_list), 20))\n",
    "average_training = np.empty((len(config_list), 20))\n",
    "average_loss = np.empty((len(config_list), 20))\n",
    "average_val_loss = np.empty((len(config_list), 20))\n",
    "i=0\n",
    "\n",
    "    \n",
    "# for each set of parameters\n",
    "for config in config_list:\n",
    "    \n",
    "    # create and fit model\n",
    "    model = make_model(config[0],config[1],config[2])\n",
    "    history = model.fit(X_train, y_train, validation_split = 0.25, epochs = 20, verbose = 0)\n",
    "    \n",
    "\n",
    "    # store training history \n",
    "    validation_history += [np.max(history.history['val_accuracy'])]\n",
    "    average_validation[i] = history.history['val_accuracy']\n",
    "    average_training[i] = history.history['accuracy']\n",
    "    average_loss[i] = history.history['loss']\n",
    "    average_val_loss[i] = history.history['val_loss']\n",
    "\n",
    "print('Best Validation Accuracy is ' + str(np.max(validation_history)))\n",
    "print('Best parameters: ' + str(config_list[np.argmax(validation_history)]))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(np.mean(average_validation, axis = 0), label = 'average validation score')\n",
    "plt.plot(np.mean(average_training, axis = 0), label = 'average training score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we try a model with 3 con2d layers and 3 dense layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a simple model\n",
    "def make_model1(kernel_sizes = (3,3,3), dense = (64,32), filters = (32,32,32)):\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Conv2D(filters[0], kernel_size=kernel_sizes[0],activation='relu',input_shape=(50,50,3)))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn.add(Conv2D(filters[1], kernel_size=kernel_sizes[1], activation='relu'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn.add(Conv2D(filters[2], kernel_size=kernel_sizes[2], activation='relu'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(dense[0], activation='relu'))\n",
    "    cnn.add(Dense(dense[1], activation='relu'))\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    cnn.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "    return cnn\n",
    "\n",
    "\n",
    "\n",
    "# parameters to tune\n",
    "filters = [(16,16,32),(16,32,64),(32,32,32)]\n",
    "kernel_sizes = [(3,3,3),(5,5,5),(7,7,7),(3,5,7),(2,2,2)]\n",
    "dense = [(512,256),(128,64),(64,32)]\n",
    "config_list = []\n",
    "for x in kernel_sizes:\n",
    "    for y in dense:\n",
    "        for z in filters:\n",
    "            config_list += [[x,y,z]]\n",
    "\n",
    "# variables to store training results    \n",
    "validation_history = []        \n",
    "average_validation = np.empty((len(config_list), 20))\n",
    "average_training = np.empty((len(config_list), 20))\n",
    "i=0\n",
    "\n",
    "    \n",
    "# for each set of parameters\n",
    "for config in config_list:\n",
    "    \n",
    "    # create and fit model\n",
    "    model = make_model1(config[0],config[1],config[2])\n",
    "    history = model.fit(X_train, y_train, validation_split = 0.25, epochs = 20, verbose = 0)\n",
    "    \n",
    "    # store training history \n",
    "    validation_history += [np.max(history.history['val_accuracy'])]\n",
    "    average_validation[i] = history.history['val_accuracy']\n",
    "    average_training[i] = history.history['accuracy']\n",
    "\n",
    "print('Best Validation Accuracy is ' + str(np.max(validation_history)))\n",
    "print('Best parameters: ' + str(config_list[np.argmax(validation_history)]))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(np.mean(average_validation, axis = 0), label = 'average validation score')\n",
    "plt.plot(np.mean(average_training, axis = 0), label = 'average training score')\n",
    "plt.plot(average_validation[np.argmax(validation_history)],\n",
    "         label = 'best parameter: ' + str(config_list[np.argmax(validation_history)]))\n",
    "plt.title('Model Accuracy for 2 Layer Model')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the improvement is so little (<0.01) in accuracy, we will stop at 3 layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "# create generator instance\n",
    "datagen = ImageDataGenerator(horizontal_flip = True,\n",
    "                             vertical_flip = True,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             zoom_range = 0.2,\n",
    "                             rotation_range = 90)\n",
    "\n",
    "# augment data\n",
    "it = datagen.flow(X_train, y_train)\n",
    "\n",
    "\n",
    "config = config_list[np.argmax(validation_history)]\n",
    "\n",
    "model_aug = make_model1(config[0],config[1],config[2])\n",
    "aug_history = model_aug.fit_generator(it, epochs = 20, verbose = 0, steps_per_epoch=646)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that data augmentation had little improvement on our model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet\n",
    "We first build a 50 layer residual network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(X, kernel_sizes, filters, skip = True):\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # 1st layer of block\n",
    "    X = Conv2D(filters = filters[0], kernel_size = (1, 1), strides = (1,1), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # 2nd layer of block\n",
    "    X = Conv2D(filters = filters[1], kernel_size = kernel_sizes, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(filters = filters[2], kernel_size = (1, 1), strides = (1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # if we are building a resnet\n",
    "    if skip:\n",
    "        X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, kernel_sizes, filters, s=2, skip = True):\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters=filters[0], kernel_size=(1, 1), strides=(s, s), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=filters[1], kernel_size=kernel_sizes, strides=(1, 1), padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=filters[2], kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters=filters[2], kernel_size=(1, 1), strides=(s, s), padding='valid')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization()(X_shortcut)\n",
    "\n",
    "    # if we are building a resnet\n",
    "    if skip:\n",
    "        X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_model(skip = True):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input((50,50,3))\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, 3, [32, 32, 32],s = 1, skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, 3, [32, 32, 32], s=2, skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    \n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, 3, [32, 32, 32],  s=2, skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    \n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, 3, [32, 32, 32], s=2, skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    X = identity_block(X, 3, [32, 32, 32], skip = skip)\n",
    "    \n",
    "    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit the model with residual connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_model()\n",
    "model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, y_train, epochs = 20,verbose = 0)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare to the model with no residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_model(False)\n",
    "model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, y_train, epochs = 20, verbose = 0)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with residual connections we get better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
